{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment_2_PartA(code for verification)_Ganesh_Kumaran_Masilamani_200434339.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZfqzG-psHbd"
      },
      "source": [
        "##**Asssignment2-PART-A-Neural Machine Translation(Verification Code)**\n",
        "\n",
        "**NAME :** Ganesh Kumaran Masilamani\n",
        "\n",
        "**STUDENT ID :** 200434339"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V5YoFP3yQO-",
        "outputId": "cf95a56b-5c72-42b1-adb5-96e9bc79a9fd"
      },
      "source": [
        "#Mounting the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upXa_erqyzKm"
      },
      "source": [
        "#change this to the path to your folder. Remember to start from the home directory\n",
        "PATH = '/MyDrive/nmt_lab_files' "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffbGcgrRy7p6"
      },
      "source": [
        "PATH_TO_FOLDER = \"/content/drive\" + PATH"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfSgKakK0QgV"
      },
      "source": [
        "import sys\n",
        "sys.path.append(PATH_TO_FOLDER)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmSgv44y0TN9"
      },
      "source": [
        "#loading the datasets\n",
        "SOURCE_PATH = PATH_TO_FOLDER + '/data.30.vi'\n",
        "TARGET_PATH = PATH_TO_FOLDER + '/data.30.en'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOTMtc_l0_ut"
      },
      "source": [
        "#importing the NMT model to the notebook\n",
        "import Assignment_2_PartA_Ganesh_Kumaran_Masilamani_200434339 as nmt "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZarpdLYcWSNl"
      },
      "source": [
        "##**Training Without Attention (use_attention=False)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsO7wW6U1w2m",
        "outputId": "48da4102-b924-47e9-cfe9-28c79d2d0cea"
      },
      "source": [
        "nmt.main(SOURCE_PATH, TARGET_PATH, use_attention=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading dictionaries\n",
            "read 24000/3000/3000 train/dev/test batches\n",
            "number of tokens in source: 2034, number of tokens in target:2506\n",
            "Task 1(a): Creating the embedding lookups...\n",
            "\n",
            "Task 1(b): Looking up source and target words...\n",
            "\n",
            "Task 1(c): Creating an encoder\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "\t\t\t\t\t\t Train Model Summary.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 100)    203400      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    250600      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, 100)    0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 100)    0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, None, 200),  240800      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 200),  240800      dropout_1[0][0]                  \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 2506)   503706      lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,439,306\n",
            "Trainable params: 1,439,306\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 100)         203400    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  [(None, None, 200), (None 240800    \n",
            "=================================================================\n",
            "Total params: 444,200\n",
            "Trainable params: 444,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            " Putting together the decoder states\n",
            "\t\t\t\t\t\t Decoder Inference Model summary\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    250600      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 100)    0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 200),  240800      dropout_1[0][0]                  \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, None, 200)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 2506)   503706      lstm_1[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 995,106\n",
            "Trainable params: 995,106\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Starting training epoch 1/10\n",
            "240/240 [==============================] - 18s 54ms/step - loss: 2.3742 - accuracy: 0.1954\n",
            "Time used for epoch 1: 0 m 17 s\n",
            "Evaluating on dev set after epoch 1/10:\n",
            "Model BLEU score: 1.44\n",
            "Time used for evaluate on dev set: 0 m 5 s\n",
            "Starting training epoch 2/10\n",
            "240/240 [==============================] - 13s 55ms/step - loss: 1.8212 - accuracy: 0.3047\n",
            "Time used for epoch 2: 0 m 13 s\n",
            "Evaluating on dev set after epoch 2/10:\n",
            "Model BLEU score: 2.55\n",
            "Time used for evaluate on dev set: 0 m 4 s\n",
            "Starting training epoch 3/10\n",
            "240/240 [==============================] - 14s 56ms/step - loss: 1.7024 - accuracy: 0.3403\n",
            "Time used for epoch 3: 0 m 13 s\n",
            "Evaluating on dev set after epoch 3/10:\n",
            "Model BLEU score: 3.78\n",
            "Time used for evaluate on dev set: 0 m 4 s\n",
            "Starting training epoch 4/10\n",
            "240/240 [==============================] - 14s 56ms/step - loss: 1.6249 - accuracy: 0.3581\n",
            "Time used for epoch 4: 0 m 13 s\n",
            "Evaluating on dev set after epoch 4/10:\n",
            "Model BLEU score: 4.09\n",
            "Time used for evaluate on dev set: 0 m 4 s\n",
            "Starting training epoch 5/10\n",
            "240/240 [==============================] - 14s 57ms/step - loss: 1.5680 - accuracy: 0.3695\n",
            "Time used for epoch 5: 0 m 13 s\n",
            "Evaluating on dev set after epoch 5/10:\n",
            "Model BLEU score: 4.75\n",
            "Time used for evaluate on dev set: 0 m 4 s\n",
            "Starting training epoch 6/10\n",
            "240/240 [==============================] - 13s 56ms/step - loss: 1.5222 - accuracy: 0.3773\n",
            "Time used for epoch 6: 0 m 13 s\n",
            "Evaluating on dev set after epoch 6/10:\n",
            "Model BLEU score: 5.13\n",
            "Time used for evaluate on dev set: 0 m 4 s\n",
            "Starting training epoch 7/10\n",
            "240/240 [==============================] - 13s 56ms/step - loss: 1.4864 - accuracy: 0.3826\n",
            "Time used for epoch 7: 0 m 13 s\n",
            "Evaluating on dev set after epoch 7/10:\n",
            "Model BLEU score: 5.01\n",
            "Time used for evaluate on dev set: 0 m 4 s\n",
            "Starting training epoch 8/10\n",
            "240/240 [==============================] - 13s 56ms/step - loss: 1.4576 - accuracy: 0.3875\n",
            "Time used for epoch 8: 0 m 13 s\n",
            "Evaluating on dev set after epoch 8/10:\n",
            "Model BLEU score: 5.45\n",
            "Time used for evaluate on dev set: 0 m 4 s\n",
            "Starting training epoch 9/10\n",
            "240/240 [==============================] - 14s 57ms/step - loss: 1.4346 - accuracy: 0.3912\n",
            "Time used for epoch 9: 0 m 13 s\n",
            "Evaluating on dev set after epoch 9/10:\n",
            "Model BLEU score: 5.44\n",
            "Time used for evaluate on dev set: 0 m 4 s\n",
            "Starting training epoch 10/10\n",
            "240/240 [==============================] - 14s 57ms/step - loss: 1.4132 - accuracy: 0.3941\n",
            "Time used for epoch 10: 0 m 13 s\n",
            "Evaluating on dev set after epoch 10/10:\n",
            "Model BLEU score: 5.49\n",
            "Time used for evaluate on dev set: 0 m 4 s\n",
            "Training finished!\n",
            "Time used for training: 3 m 6 s\n",
            "Evaluating on test set:\n",
            "Model BLEU score: 5.61\n",
            "Time used for evaluate on test set: 0 m 4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlMDC3DJi12c"
      },
      "source": [
        "##**Training with Attention (use_attention=True)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23t6wfpLkb2F",
        "outputId": "30a2c3a4-954e-4561-9a87-f508d08dc02d"
      },
      "source": [
        "nmt.main(SOURCE_PATH, TARGET_PATH, use_attention=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading dictionaries\n",
            "read 24000/3000/3000 train/dev/test batches\n",
            "number of tokens in source: 2034, number of tokens in target:2506\n",
            "Task 1(a): Creating the embedding lookups...\n",
            "\n",
            "Task 1(b): Looking up source and target words...\n",
            "\n",
            "Task 1(c): Creating an encoder\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "\t\t\t\t\t\t Train Model Summary.\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 100)    203400      input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, None, 100)    0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 100)    250600      input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 200),  240800      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, None, 100)    0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 200),  240800      dropout_3[0][0]                  \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer (None, None, 400)    0           lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 2506)   1004906     attention_layer[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 1,940,506\n",
            "Trainable params: 1,940,506\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, None, 100)         203400    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, None, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                [(None, None, 200), (None 240800    \n",
            "=================================================================\n",
            "Total params: 444,200\n",
            "Trainable params: 444,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            " Putting together the decoder states\n",
            "\t\t\t\t\t\t Decoder Inference Model summary\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 100)    250600      input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, None, 100)    0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, None, 200)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 200),  240800      dropout_3[0][0]                  \n",
            "                                                                 input_8[0][0]                    \n",
            "                                                                 input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer (None, None, 400)    0           input_10[0][0]                   \n",
            "                                                                 lstm_3[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 2506)   1004906     attention_layer[1][0]            \n",
            "==================================================================================================\n",
            "Total params: 1,496,306\n",
            "Trainable params: 1,496,306\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Starting training epoch 1/10\n",
            "240/240 [==============================] - 18s 60ms/step - loss: 2.3398 - accuracy: 0.2069\n",
            "Time used for epoch 1: 0 m 18 s\n",
            "Evaluating on dev set after epoch 1/10:\n",
            "Model BLEU score: 5.49\n",
            "Time used for evaluate on dev set: 0 m 6 s\n",
            "Starting training epoch 2/10\n",
            "240/240 [==============================] - 14s 59ms/step - loss: 1.5410 - accuracy: 0.4115\n",
            "Time used for epoch 2: 0 m 14 s\n",
            "Evaluating on dev set after epoch 2/10:\n",
            "Model BLEU score: 11.35\n",
            "Time used for evaluate on dev set: 0 m 4 s\n",
            "Starting training epoch 3/10\n",
            "240/240 [==============================] - 14s 59ms/step - loss: 1.2876 - accuracy: 0.4680\n",
            "Time used for epoch 3: 0 m 14 s\n",
            "Evaluating on dev set after epoch 3/10:\n",
            "Model BLEU score: 13.75\n",
            "Time used for evaluate on dev set: 0 m 4 s\n",
            "Starting training epoch 4/10\n",
            "240/240 [==============================] - 14s 59ms/step - loss: 1.1439 - accuracy: 0.4996\n",
            "Time used for epoch 4: 0 m 14 s\n",
            "Evaluating on dev set after epoch 4/10:\n",
            "Model BLEU score: 14.47\n",
            "Time used for evaluate on dev set: 0 m 5 s\n",
            "Starting training epoch 5/10\n",
            "240/240 [==============================] - 15s 61ms/step - loss: 1.0549 - accuracy: 0.5204\n",
            "Time used for epoch 5: 0 m 14 s\n",
            "Evaluating on dev set after epoch 5/10:\n",
            "Model BLEU score: 15.22\n",
            "Time used for evaluate on dev set: 0 m 5 s\n",
            "Starting training epoch 6/10\n",
            "240/240 [==============================] - 15s 62ms/step - loss: 0.9940 - accuracy: 0.5364\n",
            "Time used for epoch 6: 0 m 14 s\n",
            "Evaluating on dev set after epoch 6/10:\n",
            "Model BLEU score: 15.54\n",
            "Time used for evaluate on dev set: 0 m 5 s\n",
            "Starting training epoch 7/10\n",
            "240/240 [==============================] - 15s 61ms/step - loss: 0.9485 - accuracy: 0.5482\n",
            "Time used for epoch 7: 0 m 14 s\n",
            "Evaluating on dev set after epoch 7/10:\n",
            "Model BLEU score: 15.81\n",
            "Time used for evaluate on dev set: 0 m 5 s\n",
            "Starting training epoch 8/10\n",
            "240/240 [==============================] - 15s 61ms/step - loss: 0.9106 - accuracy: 0.5588\n",
            "Time used for epoch 8: 0 m 14 s\n",
            "Evaluating on dev set after epoch 8/10:\n",
            "Model BLEU score: 15.97\n",
            "Time used for evaluate on dev set: 0 m 5 s\n",
            "Starting training epoch 9/10\n",
            "240/240 [==============================] - 14s 60ms/step - loss: 0.8807 - accuracy: 0.5671\n",
            "Time used for epoch 9: 0 m 14 s\n",
            "Evaluating on dev set after epoch 9/10:\n",
            "Model BLEU score: 15.79\n",
            "Time used for evaluate on dev set: 0 m 5 s\n",
            "Starting training epoch 10/10\n",
            "240/240 [==============================] - 14s 59ms/step - loss: 0.8572 - accuracy: 0.5743\n",
            "Time used for epoch 10: 0 m 14 s\n",
            "Evaluating on dev set after epoch 10/10:\n",
            "Model BLEU score: 15.81\n",
            "Time used for evaluate on dev set: 0 m 5 s\n",
            "Training finished!\n",
            "Time used for training: 3 m 20 s\n",
            "Evaluating on test set:\n",
            "Model BLEU score: 16.43\n",
            "Time used for evaluate on test set: 0 m 5 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}